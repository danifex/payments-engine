# Payments Engine

A simple toy payments engine that processes a list of transactions and computes their effects on a set of client
accounts.

## Usage

```
cargo run -- transactions.csv > accounts.csv
```

A simple sample transactions file can be found
in [tests/test_sample_data/sample_transactions.csv](tests%2Ftest_sample_data%2Fsample_transactions.csv). A larger one
can be generated by running the [sample-data-generator](sample-data-generator) project.

## Assumptions

This implementation makes the following assumptions:

* **Only deposits are subject to disputes**
    * It's logical for clients to dispute debit/credit cards transactions that result in deposits. However,
      disputing withdrawals doesn't seem realistic
* **Disputes can be reopened after having been resolved**
* **A chargeback of already withdrawn funds can occur and can lead to a client having a negative balance**
    * Assuming disputes and consequent chargebacks might be initiated by a payments processor 3rd party, it's plausible
      that a chargeback occurs even when that would put a client with negative balance
    * A negative balance indicates the client owes money
* **Disputes, resolves and chargebacks can occur even when an account is frozen**
    * Since these actions could be initiated unilaterally by a third party, an account should still be able to process
      them even if frozen. A frozen account simply cannot receive deposits or permit withdrawals

## Development

### Float value processing

To circumvent precision issues associated with floating-point arithmetic, this engine exclusively uses integer
representations and arithmetic for transaction amounts and client account balances.

Amounts are stored in 64-bit integers, representing the smallest unit of interest (`0.001`).

### Ensuring correctness

Multiple strategies ensure the engine's correctness:

* **Unit Tests**
    * Critical code sections, such as conversion to/from float, CSV reading, and core account logic, are validated
      through unit tests
* **Integration Tests**
    * These tests execute the complete binary with a set of sample transactions and verify the output against expected
      results

### Safety

#### Panics

While generally safe, the engine may panic under certain conditions:

* Incorrect number of arguments provided
* Issues with reading the input CSV file
* Issues with writing the output CSV to stdout
* Overflow when handling very large transaction amounts (see next section, which
  covers [Casts and overflows](#casts-and-overflows))

Potential panic-resulting calls are confined to the body of `main()`. Simple error handling using `anyhow` is used to
propagate errors up to `main()`.

Any transactions that cannot be processed (e.g. invalid, not enough funds, chargeback of non-disputed deposit, etc) are
simply
ignored and an error is printed into `stderr`.

#### Casts and overflows

No safeguards are put in place in order to prevent issues with castings from `u64` to `i64` and general overflows when
making operations with transaction amounts. The premise is that `i64` is sufficiently large to accommodate a client's
balance (even taking into account the 4 additional decimal places, the max amount is nearly a quadrillion).

### Efficiency

This engine takes advantage of the `csv` crate and it's streaming interface to avoid loading the entire input
csv file into memory.

Some data still needs to be kept in memory while processing the transactions, namely all the client accounts states, as
well as all previous deposits so that potential disputes, resolves and chargebacks can be processed later. Given there's
no guarantees on the order of transactions, `HashMaps` were used to store both account data and previous deposits data.

Basic profiling using GNU's `time` was used in order to check runtimes and memory usage when running against a larger
dataset (generated using [sample-data-generator](sample-data-generator)). The implementation is IO-bound with roughly
80%
of time being spent reading the csv file. Memory usage can be slightly reduced by flattening nested `HashMaps` (see
branch `flattened-hashmaps`), but there's a tradeoff in more compute time and less readable code which was not deemed
worthwhile.

With some care, it would be possible to parallelize the processing of transactions (as long the implementation
guarantees transactions from the same
account are processed in the right order). This idea wasn't pursued because the
current solution is not compute bound.

If this was to be used in a server context, the `Engine` struct could easily be shared between multiple transaction
processing tasks as long as they were guaranteed to not have overlaps in the accounts they affect. If that assumption is
dropped, a locking mechanism could be used on the `Account` level to ensure sequential access, but in that case it would
be hard to know the ordering without
explicit timestamping of the input transactions.
